{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type\n",
      "harmful    900\n",
      "safe       900\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"u_malicious_url.csv\")\n",
    "# df.head()\n",
    "\n",
    "# df_sample = df.head(5000) \n",
    "df_sample = df.groupby(\"Type\").sample(n=900)\n",
    "print(df_sample[\"Type\"].value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(url):\n",
    "\n",
    "    feature = {}\n",
    "\n",
    "    # URL Length\n",
    "    feature['url_length'] = len(url)\n",
    "\n",
    "    # Count Special Character\n",
    "    feature['num_special_chars'] = sum(1 for c in url if c in['?', '=', '&', '%', '@', '-', '_'])\n",
    "\n",
    "    # Count Digits\n",
    "    feature['num_digit'] = sum(c.isdigit() for c in url)\n",
    "\n",
    "    # Count subdomains (number of dots in URL)\n",
    "    feature['num_subdomains'] = url.count('.')\n",
    "    \n",
    "    # Extract domain & path \n",
    "    parsed_url = urlparse(url)\n",
    "    # feature['domain'] = parsed_url.netloc # Extract domain\n",
    "    feature['path_length'] = len(parsed_url.path) # Path length\n",
    "    feature['num_path_segments'] = parsed_url.path.count('/') # Count path segments\n",
    "\n",
    "    # Check if URL contains suspicious keywords\n",
    "    suspicious_keywords = ['pay', '.io', 'login', 'secure', 'wallet', 'auth', 'support', 'block']\n",
    "    feature['num_suspicious_keywords'] = sum(1 for keyword in suspicious_keywords if keyword in url)\n",
    "\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>url_length</th>\n",
       "      <th>num_special_chars</th>\n",
       "      <th>num_digit</th>\n",
       "      <th>num_subdomains</th>\n",
       "      <th>path_length</th>\n",
       "      <th>num_path_segments</th>\n",
       "      <th>num_suspicious_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>harmful</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>harmful</td>\n",
       "      <td>77</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>harmful</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>harmful</td>\n",
       "      <td>91</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>harmful</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Type  url_length  num_special_chars  num_digit  num_subdomains  \\\n",
       "0  harmful          40                  0          0               2   \n",
       "1  harmful          77                  4          7               3   \n",
       "2  harmful          48                  0          0               3   \n",
       "3  harmful          91                  6          9               3   \n",
       "4  harmful          35                  1         12               4   \n",
       "\n",
       "   path_length  num_path_segments  num_suspicious_keywords  \n",
       "0           24                  3                        0  \n",
       "1           33                  5                        0  \n",
       "2           15                  2                        0  \n",
       "3           62                  4                        0  \n",
       "4           15                  1                        0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply feature extraction to all URLs\n",
    "features_df = df_sample['URL'].apply(lambda x: extract_features(x)).apply(pd.Series)\n",
    "\n",
    "# Merge extracted features with the sampled dataset\n",
    "df_sample = df_sample.reset_index(drop=True)  \n",
    "features_df = features_df.reset_index(drop=True) \n",
    "df_sample = pd.concat([df_sample, features_df], axis=1)\n",
    "\n",
    "# Drop the 'url' column from df_sample\n",
    "df_sample = df_sample.drop(columns=['URL'])\n",
    "\n",
    "# Save the cleaned sampled dataset\n",
    "# df_sample.to_csv(\"sample_malicious_url.csv\", index=False)\n",
    "df_sample.to_csv(\"training_malicious_url.csv\", index=False)\n",
    "\n",
    "# Display the first few rows of the cleaned dataset\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Read the data\n",
    "# df = pd.read_csv(\"malicious_url.csv\")\n",
    "\n",
    "# # Define the number of samples to take for each class\n",
    "# samples_per_class = {\n",
    "#     \"benign\": 5000,\n",
    "#     \"malware\": 1666,\n",
    "#     \"phishing\": 1666,  # Example for another class, adjust as needed\n",
    "#     \"defacement\": 1666  # Example for another class, adjust as needed\n",
    "# }\n",
    "\n",
    "# # Create a list to store the resampled dataframes\n",
    "# df_sampled = []\n",
    "\n",
    "# # Loop through each class and sample the defined number of records\n",
    "# for label, num_samples in samples_per_class.items():\n",
    "#     df_class = df[df['Type'] == label]\n",
    "#     df_class_sampled = df_class.sample(n=num_samples, random_state=42)\n",
    "#     df_sampled.append(df_class_sampled)\n",
    "\n",
    "# # Concatenate all the resampled dataframes into one\n",
    "# df_sample = pd.concat(df_sampled)\n",
    "\n",
    "# # Check the class distribution of the sampled data\n",
    "# print(df_sample['type'].value_counts())\n",
    "\n",
    "# df_sample.to_csv(\"new_url_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"malicious_url.csv\")\n",
    "# df.head()\n",
    "\n",
    "# df_sample = df.groupby(\"type\").sample(n=1250)\n",
    "# print(df_sample[\"type\"].value_counts()) \n",
    "\n",
    "# df_sample.to_csv(\"new_url_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type\n",
      "harmful    250\n",
      "safe       250\n",
      "Name: count, dtype: int64\n",
      "Type\n",
      "harmful    250\n",
      "safe       250\n",
      "Name: count, dtype: int64\n",
      "Combined dataset shape: (1000, 2)\n",
      "                                             Content     Type\n",
      "0  URGENT. Important information for 02 user. Tod...  harmful\n",
      "1  Do you want a NEW video phone750 anytime any n...  harmful\n",
      "2  Promotion Number: 8714714 - UR awarded a City ...  harmful\n",
      "3  Congrats! 2 mobile 3G Videophones R yours. cal...  harmful\n",
      "4  Twinks, bears, scallies, skins and jocks are c...  harmful\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"../c_spam_text.csv\")\n",
    "df2 = pd.read_csv(\"../c_malicious_url.csv\")\n",
    "\n",
    "df1_sample = df1.groupby(\"Type\").sample(n=250)\n",
    "print(df1_sample[\"Type\"].value_counts()) \n",
    "\n",
    "df2_sample = df2.groupby(\"Type\").sample(n=250)\n",
    "print(df2_sample[\"Type\"].value_counts()) \n",
    "\n",
    "# Concatenate the datasets\n",
    "df_combined = pd.concat([df1_sample, df2_sample], ignore_index=True)\n",
    "\n",
    "# Save the combined dataset\n",
    "df_combined.to_csv(\"combined_dataset.csv\", index=False)\n",
    "\n",
    "print(\"Combined dataset shape:\", df_combined.shape)\n",
    "print(df_combined.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
